const { withXcodeProject } = require('@expo/config-plugins');
const fs = require('fs');
const path = require('path');

/**
 * EXPO CONFIG PLUGIN EXPLANATION
 * 
 * This plugin runs during EAS prebuild phase and:
 * 1. Creates your native Swift/Objective-C files
 * 2. Adds them to the Xcode project
 * 3. Configures build settings
 * 4. Registers them for compilation
 */

function withTrueDepthFrameProcessor(config) {
  // STEP 1: Use withXcodeProject to modify the iOS project
  return withXcodeProject(config, async (config) => {
    console.log('üîß Running TrueDepthFrameProcessor config plugin...');
    
    const { projectRoot } = config.modRequest;
    const xcodeProject = config.modResults;
    
    // Get the app name from config for proper Swift bridging header
    const appName = config.name || 'frontend';
    
    // STEP 2: Define your native file contents
    // This is your Objective-C bridge file
    const mFileContent = `
#if __has_include(<VisionCamera/FrameProcessorPlugin.h>)
#pragma message "‚úÖ VisionCamera headers found - ENTERING IF BLOCK"

#import <VisionCamera/FrameProcessorPlugin.h>
#import <VisionCamera/FrameProcessorPluginRegistry.h>

#pragma message "‚úÖ FrameProcessorPlugin.h imported successfully"

// Import Swift bridging header (auto-generated by Xcode)
#if __has_include("${appName}-Swift.h")
#pragma message "‚úÖ Swift bridging header found"
#import "${appName}-Swift.h"
#pragma message "‚úÖ Swift bridging header imported successfully"
#else
#pragma message "‚ùå Swift bridging header NOT found"
#warning "Swift bridging header not found - check project name"
#endif

// Debug class to verify loading
@interface TrueDepthFrameProcessorBridge : NSObject
@end

@implementation TrueDepthFrameProcessorBridge

+ (void)load {
    NSLog(@"üîµ TrueDepthFrameProcessorBridge: Objective-C bridge loaded");
    
    // Verify VisionCamera is loaded
    Class visionCameraClass = NSClassFromString(@"CameraView");
    if (visionCameraClass) {
        NSLog(@"‚úÖ VisionCamera CameraView class found");
    } else {
        NSLog(@"‚ùå VisionCamera CameraView class NOT found");
    }
    
    // Check if our Swift class exists
    Class swiftClass = NSClassFromString(@"TrueDepthFrameProcessor");
    if (swiftClass) {
        NSLog(@"‚úÖ Swift TrueDepthFrameProcessor class found");
        NSLog(@"üéâ Plugin registration should succeed!");
    } else {
        NSLog(@"‚ùå Swift TrueDepthFrameProcessor class NOT found");
        NSLog(@"üí• Plugin registration will fail!");
    }
}

@end

// STEP 3: Register the plugin with VisionCamera
// This macro creates the JavaScript-to-Swift bridge
#pragma message "Registering TrueDepthFrameProcessor with VisionCamera..."
VISION_EXPORT_SWIFT_FRAME_PROCESSOR(TrueDepthFrameProcessor, trueDepthFrameProcessor)
#pragma message "‚úÖ VISION_EXPORT_SWIFT_FRAME_PROCESSOR called"

#else
#pragma message "‚ùå‚ùå‚ùå VisionCamera headers NOT FOUND ‚ùå‚ùå‚ùå"
#error "VisionCamera FrameProcessorPlugin.h not found. Ensure enableFrameProcessors is true."
#endif`;

    // STEP 4: Define your Swift implementation
    const swiftFileContent = `import VisionCamera
import Foundation

/**
 * Custom Frame Processor for TrueDepth camera analysis
 * 
 * This class extends FrameProcessorPlugin and implements the callback method
 * that gets called for each camera frame when trueDepthFrameProcessor() 
 * is called from JavaScript.
 */
@objc(TrueDepthFrameProcessor)
public class TrueDepthFrameProcessor: FrameProcessorPlugin {
    
    /**
     * Called for each camera frame when trueDepthFrameProcessor() is invoked in JS
     * 
     * @param frame: The camera frame data
     * @param arguments: Optional parameters passed from JavaScript
     * @return: Data to send back to JavaScript (must be JSON-serializable)
     */
    public override func callback(_ frame: Frame, withArguments arguments: [AnyHashable : Any]?) -> Any? {
        print("üî• TrueDepthFrameProcessor: Processing frame...")
        print("üìê Frame dimensions: \\(frame.width) x \\(frame.height)")
        print("‚è±Ô∏è Frame timestamp: \\(frame.timestamp)")
        
        // Extract any parameters passed from JavaScript
        let processingMode = arguments?["mode"] as? String ?? "default"
        print("üéØ Processing mode: \\(processingMode)")
        
        // YOUR CUSTOM PROCESSING LOGIC GOES HERE
        // Example: Face detection, depth analysis, etc.
        
        // Simulate some processing time for demo
        let processingStartTime = Date()
        
        // Create result data to return to JavaScript
        let result: [String: Any] = [
            "width": frame.width,
            "height": frame.height,
            "timestamp": frame.timestamp,
            "processingMode": processingMode,
            "processingTime": Date().timeIntervalSince(processingStartTime) * 1000, // ms
            "status": "success",
            "frameFormat": frame.pixelFormat.description
        ]
        
        print("üìä Returning result: \\(result)")
        return result
    }
    
    /**
     * Plugin initialization - called when plugin is first loaded
     * 
     * @param proxy: VisionCamera proxy for advanced features
     * @param options: Initialization options from JavaScript
     */
    public override init(proxy: VisionCameraProxyHolder, options: [AnyHashable : Any]? = nil) {
        super.init(proxy: proxy, options: options)
        
        print("üü¢ TrueDepthFrameProcessor: Plugin initialized!")
        
        if let options = options {
            print("‚öôÔ∏è Initialization options: \\(options)")
        }
        
        // You can perform one-time setup here
        setupProcessor()
    }
    
    /**
     * Private method for setting up the processor
     */
    private func setupProcessor() {
        print("üîß Setting up TrueDepth frame processor...")
        // Initialize ML models, allocate buffers, etc.
    }
    
    deinit {
        print("üî¥ TrueDepthFrameProcessor: Plugin deallocated")
    }
}`;

    // STEP 5: Determine target iOS directory and project name
    const iosDir = path.join(projectRoot, 'ios');
    const projectName = appName; // Use the app name as project name
    
    // STEP 6: Create iOS directory if it doesn't exist
    if (!fs.existsSync(iosDir)) {
      console.log('üìÅ Creating ios directory...');
      fs.mkdirSync(iosDir, { recursive: true });
    }
    
    // STEP 7: Write the native files to iOS project directory
    // Files should go in the project subdirectory, not the root ios directory
    const projectDir = path.join(iosDir, projectName);
    if (!fs.existsSync(projectDir)) {
      console.log(`üìÅ Creating project directory: ${projectDir}`);
      fs.mkdirSync(projectDir, { recursive: true });
    }
    
    const mFilePath = path.join(projectDir, 'TrueDepthFrameProcessor.m');
    const swiftFilePath = path.join(projectDir, 'TrueDepthFrameProcessor.swift');
    
    console.log('üìù Writing TrueDepthFrameProcessor.m...');
    fs.writeFileSync(mFilePath, mFileContent);
    
    console.log('üìù Writing TrueDepthFrameProcessor.swift...');
    fs.writeFileSync(swiftFilePath, swiftFileContent);
    
    // STEP 8: Generate unique UUIDs for Xcode project references
    const mFileRef = xcodeProject.generateUuid();
    const swiftFileRef = xcodeProject.generateUuid();
    const mBuildFile = xcodeProject.generateUuid();
    const swiftBuildFile = xcodeProject.generateUuid();
    
    console.log('üîó Adding files to Xcode project...');
    
    // STEP 9: Add files to PBXFileReference section with proper paths
    xcodeProject.addToPbxFileReferenceSection({
      uuid: mFileRef,
      basename: 'TrueDepthFrameProcessor.m',
      lastKnownFileType: 'sourcecode.c.objc',
      name: 'TrueDepthFrameProcessor.m',
      path: 'TrueDepthFrameProcessor.m',
      sourceTree: '"<group>"'
    });
    
    xcodeProject.addToPbxFileReferenceSection({
      uuid: swiftFileRef,
      basename: 'TrueDepthFrameProcessor.swift',
      lastKnownFileType: 'sourcecode.swift',
      name: 'TrueDepthFrameProcessor.swift',
      path: 'TrueDepthFrameProcessor.swift',
      sourceTree: '"<group>"'
    });
    
    // STEP 10: Add files to PBXBuildFile section
    xcodeProject.addToPbxBuildFileSection({
      uuid: mBuildFile,
      fileRef: mFileRef,
      settings: {}
    });
    
    xcodeProject.addToPbxBuildFileSection({
      uuid: swiftBuildFile,
      fileRef: swiftFileRef,
      settings: {}
    });
    
    // STEP 11: Get the main app target
    const target = xcodeProject.getFirstTarget();
    if (!target) {
      throw new Error('‚ùå Could not find main app target');
    }
    
    // Get target UUID properly
    const targetUuid = target.uuid;
    const targetName = target.firstTarget?.name || target.name || 'Unknown';
    console.log(`üéØ Adding files to target: ${targetName} (${targetUuid})`);
    
    // STEP 12: Add files to Sources build phase
    const sourcesBuildPhase = xcodeProject.buildPhaseObject('PBXSourcesBuildPhase', 'Sources', targetUuid);
    if (sourcesBuildPhase) {
      sourcesBuildPhase.files = sourcesBuildPhase.files || [];
      
      // Add Objective-C file
      sourcesBuildPhase.files.push({
        value: mBuildFile,
        comment: 'TrueDepthFrameProcessor.m in Sources'
      });
      
      // Add Swift file  
      sourcesBuildPhase.files.push({
        value: swiftBuildFile,
        comment: 'TrueDepthFrameProcessor.swift in Sources'
      });
      
      console.log('‚úÖ Files added to Sources build phase');
    } else {
      console.warn('‚ö†Ô∏è Could not find Sources build phase');
    }
    
    // STEP 13: Add files to the project group structure
    try {
      const mainGroup = xcodeProject.getFirstProject().firstProject.mainGroup;
      const projectGroup = xcodeProject.pbxGroupByName(projectName);
      
      if (projectGroup) {
        projectGroup.children = projectGroup.children || [];
        
        // Add file references to the project group
        projectGroup.children.push({
          value: mFileRef,
          comment: 'TrueDepthFrameProcessor.m'
        });
        
        projectGroup.children.push({
          value: swiftFileRef,
          comment: 'TrueDepthFrameProcessor.swift'
        });
        
        console.log('‚úÖ Files added to project group');
      } else {
        console.warn('‚ö†Ô∏è Could not find project group');
      }
    } catch (error) {
      console.warn('‚ö†Ô∏è Could not add files to project group:', error.message);
    }
    
    // STEP 14: Configure Swift and build settings
    const buildConfigurations = xcodeProject.pbxXCBuildConfigurationSection();
    for (const key in buildConfigurations) {
      const config = buildConfigurations[key];
      if (config.buildSettings) {
        // Ensure Swift is enabled
        config.buildSettings.SWIFT_VERSION = config.buildSettings.SWIFT_VERSION || '5.0';
        config.buildSettings.ALWAYS_EMBED_SWIFT_STANDARD_LIBRARIES = 'YES';
        
        // Ensure Objective-C bridging header is properly configured
        if (!config.buildSettings.SWIFT_OBJC_BRIDGING_HEADER) {
          config.buildSettings.SWIFT_OBJC_BRIDGING_HEADER = `${projectName}/${projectName}-Bridging-Header.h`;
        }
        
        // Enable Swift-ObjC interoperability
        config.buildSettings.SWIFT_OBJC_INTERFACE_HEADER_NAME = `${projectName}-Swift.h`;
      }
    }
    
    console.log('üéâ TrueDepthFrameProcessor plugin integration complete!');
    console.log('üìã Summary:');
    console.log(`  - Created ${projectName}/TrueDepthFrameProcessor.m`);
    console.log(`  - Created ${projectName}/TrueDepthFrameProcessor.swift`);
    console.log('  - Added files to Xcode project');
    console.log('  - Added files to Sources build phase');
    console.log('  - Added files to project group');
    console.log('  - Configured Swift build settings');
    console.log('  - Enabled Swift-ObjC interoperability');
    
    return config;
  });
}

module.exports = withTrueDepthFrameProcessor;